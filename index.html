<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>I&S project Sonya</title>
  <script src="https://unpkg.com/ml5@latest/dist/ml5.min.js"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      display: flex;
      align-items: center;
      justify-content: center;
      height: 100vh;
      background-color: #ffffff;
      /* Change background color to white */
    }

    canvas,
    video {
      display: block;
      margin: auto;
      position: absolute;
      top: 0;
      left: 0;
    }


    #video-visualizer {
      width: 100vw;
      /* Full screen width */
      height: 100vh;
      /* Full screen height */
    }

  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.7.0/p5.js"></script>
  <script type="module">
    let sketch = function (p) {
      const size = 9;
      const width = window.innerWidth; // Full screen width
      const height = window.innerHeight; // Full screen height
      const cols = width / size;
      const rows = height / size;

      const symbols = ["𝄪", "𝄞", "♯", "𝄡", "𝄫", "𝄢"];
      let faceapi;
      let detections;
      // by default all options are set to true
        const detectionOptions = {
        withLandmarks: true,
        withDescriptors: false,
        };

      let video;

      p.setup = function () {
        p.createCanvas(window.innerWidth, window.innerHeight); // Full screen canvas dimensions
        video = p.createCapture(p.VIDEO);
        video.size(parseInt(window.innerWidth/4), parseInt(window.innerHeight/4)); // Full screen video size
        video.hide();
        faceapi = ml5.faceApi(video, detectionOptions, modelReady);
      };

      function modelReady() {
        console.log("ready!");
        console.log(faceapi);
        faceapi.detect(gotResults);
        }

    function gotResults(err, result) {
        if (err) {
            console.log(err);
            return;
        }
        // console.log(result)
        detections = result;

        // background(220);
        p.background(255);
        // image(video, 0, 0, width, height);
        if (detections) {
            if (detections.length > 0) {
            // console.log(detections)
            drawBox(detections);
            drawLandmarks(detections);
            }
        }
        faceapi.detect(gotResults);
        }
        function drawBox(detections) {
  for (let i = 0; i < detections.length; i += 1) {
    const alignedRect = detections[i].alignedRect;
    const x = alignedRect._box._x;
    const y = alignedRect._box._y;
    const boxWidth = alignedRect._box._width;
    const boxHeight = alignedRect._box._height;

    p.noFill();
    p.stroke(161, 95, 251);
    p.strokeWeight(2);
    p.rect(x, y, boxWidth, boxHeight);
  }
}

function drawLandmarks(detections) {
  p.noFill();
  p.stroke(161, 95, 251);
  p.strokeWeight(2);

  for (let i = 0; i < detections.length; i += 1) {
    const mouth = detections[i].parts.mouth;
    const nose = detections[i].parts.nose;
    const leftEye = detections[i].parts.leftEye;
    const rightEye = detections[i].parts.rightEye;
    const rightEyeBrow = detections[i].parts.rightEyeBrow;
    const leftEyeBrow = detections[i].parts.leftEyeBrow;

    drawPart(mouth, true);
    drawPart(nose, false);
    drawPart(leftEye, true);
    drawPart(leftEyeBrow, false);
    drawPart(rightEye, true);
    drawPart(rightEyeBrow, false);
  }
}

function drawPart(feature, closed) {
  p.beginShape();
  for (let i = 0; i < feature.length; i += 1) {
    const x = feature[i]._x;
    const y = feature[i]._y;
    p.vertex(x, y);
  }

  if (closed === true) {
    p.endShape(p.CLOSE);
  } else {
    p.endShape();
  }
}
      p.draw = function () {
        p.background(255, 255, 255);
        video.loadPixels();

        for (let i = 0; i < cols; i++) {
          for (let j = 0; j < rows; j++) {
            let index = (j * size * width + i * size) * 4;
            let r = video.pixels[index];
            let g = video.pixels[index + 1];
            let b = video.pixels[index + 2];
            let average = (r + g + b) / 3;
            let symbolIndex = Math.floor(p.map(average, 0, 255, 0, symbols.length - 1));

            let gradientColor = p.color(p.map(i, 0, cols - 1, 255, 0), 255, 255);

            p.textAlign(p.RIGHT, p.CENTER);
            p.fill(gradientColor);
            p.text(symbols[symbolIndex], (cols - i - 1) * size, j * size);
          }
        }
      };

      p.windowResized = function () {
        p.resizeCanvas(window.innerWidth, window.innerHeight); // Full screen canvas dimensions
      };
    };

    let myp5 = new p5(sketch);
  </script>
</head>

<body>
</body>
</html>
